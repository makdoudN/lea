rl:
  cls: rl.lea:TD3_LEA
  kwargs:
      # -----------------
      # TD3.
      # -----------------
      action_noise_clip: 0.5
      action_noise: 0.2
      actor_update_freq: 2
      # ------------------
      # LEA.
      # ------------------
      pi_reuse: 0.2
      num_commit: 1
      reuse: false
      lam_pi_guidance: 1
      use_q_guidance: true
      use_pi_guidance: false


actor:
  cls: rltk.nn.mlp_deterministic_policy:MLPPolicy
  kwargs:
    input_nd: ${env.observation_nd}
    action_nd: ${env.action_nd}
    mlp_hidden_len:
      - 256
      - 256
actor_optim:
  cls: torch.optim:RMSprop
  kwargs:
    lr: 1e-3

critic:
  cls: rltk.nn.mlp_value:MLPDoubleActionValue
  kwargs:
    input_nd: ${env.observation_nd}
    action_nd: ${env.action_nd}
    mlp_hidden_len:
      - 256
      - 256
critic_optim:
  cls: torch.optim:RMSprop
  kwargs:
    lr: 1e-3
