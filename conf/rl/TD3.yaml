rl:
  cls: rl.ddpg:TD3
  kwargs:
    # -----------------
    # TD3.
    # -----------------
    action_noise_clip: 0.5
    action_noise: 0.2
    actor_update_freq: 2

actor:
  cls: rltk.nn.mlp_deterministic_policy:MLPPolicy
  kwargs:
    input_nd: ${env.observation_nd}
    action_nd: ${env.action_nd}
    mlp_hidden_len:
      - 256
      - 256
actor_optim:
  cls: torch.optim:RMSprop
  kwargs:
    lr: 1e-3

critic:
  cls: rltk.nn.mlp_value:MLPActionValue
  kwargs:
    input_nd: ${env.observation_nd}
    action_nd: ${env.action_nd}
    mlp_hidden_len:
      - 256
      - 256
critic_optim:
  cls: torch.optim:RMSprop
  kwargs:
    lr: 1e-3
